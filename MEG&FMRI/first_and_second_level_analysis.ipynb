{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "now = datetime.now()\n",
    "print('Starting cell:',now.strftime(\"%H:%M:%S\"))\n",
    "import os\n",
    "import pip\n",
    "os.system('python3 -m pip install numpy')\n",
    "os.system('python3 -m pip install matplotlib')\n",
    "os.system('python3 -m pip install scipy')\n",
    "os.system('python3 -m pip install panda')\n",
    "os.system('python3 -m pip install nilearn')\n",
    "os.system('python3 -m pip install pickle')\n",
    "os.system('python3 -m pip install atlasreader')\n",
    "os.system('python3 -m pip install mne')\n",
    "#import os.path as op\n",
    "#import numpy as np\n",
    "#from numpy.linalg import inv\n",
    "#import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "from nilearn import image\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting files from the BIDS structure as well as getting the friston 24 confounds to the models\n",
    "%matplotlib inline\n",
    "\n",
    "now = datetime.now()\n",
    "print('Finishing cell:',now.strftime(\"%H:%M:%S\"))\n",
    "\n",
    "def list_files(startpath):\n",
    "    \"\"\" Simple function to show directory tree. \n",
    "    From: https://stackoverflow.com/questions/9727673/list-directory-tree-structure-in-python. \"\"\"\n",
    "    for root, dirs, files in os.walk(startpath):\n",
    "        level = root.replace(startpath, '').count(os.sep)\n",
    "        indent = ' ' * 4 * (level)\n",
    "        print('{}{}/'.format(indent, os.path.basename(root)))\n",
    "        subindent = ' ' * 4 * (level + 1)\n",
    "        for f in sorted(files):\n",
    "            print('{}{}'.format(subindent, f))\n",
    "            \n",
    "data_dir='/work/MEG_exam/82777/BIDS/' \n",
    "derivatives_dir=  '/work/MEG_exam/82777/BIDS/derivatives/'          \n",
    "list_files(derivatives_dir)\n",
    "\n",
    "\n",
    "from nilearn.glm.first_level import first_level_from_bids\n",
    "\n",
    "#BIDS directory\n",
    "data_dir='/work/MEG_exam/82777/BIDS/'\n",
    "# BIDS derivatives (contains preprocessed data)\n",
    "derivatives_dir='/work/MEG_exam/82777/BIDS/derivatives' \n",
    "# Name for experiment in the BIDS directory\n",
    "task_label = 'EPIsequencewords'\n",
    "# Label for data that are spatially aligned to the MNI152 template (i.e. spatially normalised)\n",
    "space_label ='MNI152NLin2009cAsym'\n",
    "#Run the function that can gather all the needed info from a BIDS folder\n",
    "models, models_run_imgs, models_events, models_confounds = \\\n",
    "    first_level_from_bids(\n",
    "        data_dir, task_label, derivatives_folder=derivatives_dir, n_jobs=6, verbose=1,\n",
    "        img_filters=[('desc', 'preproc')])\n",
    "\n",
    "#Print the data from the first participant as sanity check\n",
    "print(models_run_imgs[0])\n",
    "\n",
    "now = datetime.now()\n",
    "print('Finishing cell:',now.strftime(\"%H:%M:%S\"))\n",
    "\n",
    "\n",
    "confound_friston24_GSR = ['global_signal','global_signal_derivative1','global_signal_power2','global_signal_derivative1_power2','trans_x','trans_y','trans_z',\n",
    "                 'rot_x','rot_y','rot_z','trans_x_derivative1','trans_y_derivative1','trans_z_derivative1',\n",
    "                 'rot_x_derivative1','rot_y_derivative1','rot_z_derivative1','trans_x_power2','trans_y_power2','trans_z_power2',\n",
    "                 'rot_x_power2','rot_y_power2','rot_z_power2']\n",
    "\n",
    "# Subset confounds with selection\n",
    "for ii in range(len(models_confounds)):\n",
    "    confounds1=models_confounds[ii][:].copy()\n",
    "    for i in range(len(confounds1)):\n",
    "        confounds2=confounds1[i].copy()\n",
    "        confounds2=confounds2[confound_friston24_GSR]\n",
    "        #Removing NAs in the first row.\n",
    "        confounds2.loc[0,:]=confounds2.loc[1,:]\n",
    "        confounds1[i]=confounds2\n",
    "    models_confounds[ii][:]=confounds1\n",
    "\n",
    "\n",
    "#Print new confounds, for first participant, first run\n",
    "print(models_confounds[0][0].columns)\n",
    "\n",
    "now = datetime.now()\n",
    "print('Finishing cell:',now.strftime(\"%H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(models_events[0][0].columns)\n",
    "\n",
    "events_sub= ['onset','duration','trial_type1']\n",
    "\n",
    "\n",
    "# Subset confounds with selection\n",
    "for ii in range(len(models_events)):\n",
    "    events1=models_events[ii][:]\n",
    "    for i in range(len(events1)):\n",
    "        events2=events1[i]\n",
    "        events2=events2[events_sub]\n",
    "        events1[i]=events2\n",
    "    models_events[ii][:]=events1\n",
    "\n",
    "\n",
    "#Print new confounds, for first participant, first run\n",
    "print(models_events[0][0].columns)\n",
    "\n",
    "now = datetime.now()\n",
    "print('Finishing cell:',now.strftime(\"%H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#taking our own trial_type1's concrete and abstract, that is making it trial_type1 as else nilearn doesn't work\n",
    "#look that counts fits with 60 trials\n",
    "print(models_events[0][0]['trial_type1'].value_counts())\n",
    "\n",
    "\n",
    "for i in range(len(models_events)):\n",
    "    print(\"id = \",i)\n",
    "    for ii in range(len(models_events[0])):\n",
    "        print(\"run = \", ii)\n",
    "        try:\n",
    "            models_events[i][ii].rename(columns = {'trial_type1':'trial_type'}, inplace = True)\n",
    "            #one subject with 5 runs....\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fitting all participants in one go\n",
    "from nilearn.plotting import plot_contrast_matrix\n",
    "from scipy.stats import norm\n",
    "p001_unc = norm.isf(0.001)\n",
    "from nilearn import plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "now = datetime.now()\n",
    "print('Starting cell:',now.strftime(\"%H:%M:%S\"))\n",
    "\n",
    "fig, axes = plt.subplots(nrows=5, ncols=5, figsize=(20, 20)) \n",
    "i = -1\n",
    "model_and_args = zip(models, models_run_imgs, models_events, models_confounds)\n",
    "for m_idx, (model, imgs, events, confounds) in enumerate(model_and_args):\n",
    "\n",
    "    # fit the GLM, recall that the model variable is a FirstLevelModel object\n",
    "    model.fit(imgs, events, confounds)\n",
    "    # compute the contrast of interest and make a map of z-values\n",
    "    model.zmap = model.compute_contrast('concrete-abstract')\n",
    "    #Plot each thresholded analysis\n",
    "    plotting.plot_glass_brain(model.zmap, cmap='jet',colorbar=True, threshold=p001_unc,\n",
    "                              title=('sub-' + model.subject_label),\n",
    "                              axes=axes[int(m_idx / 5), int(m_idx % 5)],\n",
    "                              plot_abs=False, display_mode='x')\n",
    "\n",
    "   \n",
    "fig.suptitle('subjects z_map image diff (unc p<0.001)')\n",
    "plotting.show()\n",
    "\n",
    "\n",
    "now = datetime.now()\n",
    "\n",
    "print('Finishing cell:',now.strftime(\"%H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving\n",
    "import pickle\n",
    "f = open('/work/MEG_exam/WordFace_first_level_modelss.pkl', 'rb')\n",
    "models, models_run_imgs, models_events, models_confounds = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#second level analysis:\n",
    "\n",
    "from nilearn.glm.second_level import SecondLevelModel\n",
    "#We will simply add the models estimated above to the second level\n",
    "\n",
    "#second_level_input = models\n",
    "\n",
    "#NB idx11 has different resolution for some reason\n",
    "second_level_input = models[0:11]+models[12:]\n",
    "\n",
    "#Adding the smoothing parameter\n",
    "second_level_model = SecondLevelModel(smoothing_fwhm=8.0)\n",
    "second_level_model = second_level_model.fit(second_level_input)\n",
    "\n",
    "print(second_level_model)\n",
    "\n",
    "now = datetime.now()\n",
    "print('Finishing cell:',now.strftime(\"%H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zmap_g = second_level_model.compute_contrast(\n",
    "    first_level_contrast='concrete-abstract')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting second level:\n",
    "from nilearn.plotting import plot_stat_map\n",
    "import matplotlib\n",
    "from scipy.stats import norm\n",
    "p001_unc = norm.isf(0.001)\n",
    "fig = plt.figure(figsize=(10, 5))\n",
    "\n",
    "plotting.plot_glass_brain(zmap_g, cmap='PiYG',colorbar=True, threshold=p001_unc,\n",
    "                          title='Group level effect of [concrete-abstract] effect (unc p < 0.001)',\n",
    "                          plot_abs=False, figure = fig, display_mode = \"lyrz\")\n",
    "plt.show()\n",
    "\n",
    "plot_stat_map(zmap_g, cmap='cold_hot',threshold=p001_unc, cut_coords=[-30,-20,-10,0,10,20,30],\n",
    "              display_mode='z',  black_bg=False,\n",
    "              title='Group [concrete-abstract] effect (unc p < 0.001)')\n",
    "plt.show()\n",
    "\n",
    "now = datetime.now()\n",
    "print('Finishing cell:',now.strftime(\"%H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with correction for multiple comparison:\n",
    "from nilearn.glm import threshold_stats_img\n",
    "from nilearn.plotting import plot_stat_map\n",
    "from nilearn.reporting import get_clusters_table\n",
    "from nilearn.image import mean_img\n",
    "\n",
    "thresholded_map, threshold = threshold_stats_img(\n",
    "    zmap_g, alpha=0.05, height_control='bonferroni')\n",
    "print('The p<.05 FWER-corrected threshold is %.3g' % threshold)\n",
    "\n",
    "plotting.plot_glass_brain(zmap_g, cmap='PiYG',colorbar=True, threshold=threshold,\n",
    "                          title='Group [concrete-abstract] effect (p<0.05,Bonferroni-corrected)',\n",
    "                          plot_abs=False)\n",
    "plt.show()\n",
    "\n",
    "# Make a table of cluster coordinates.\n",
    "table = get_clusters_table(zmap_g, stat_threshold=threshold)\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting tables:\n",
    "import pandas as pd\n",
    "from atlasreader import create_output\n",
    "create_output(zmap_g, voxel_thresh=threshold, cluster_extent=0,direction='both')\n",
    "#Atlasreader automatically saves results to both .png-files and a csv-file. Look in your working directory.\n",
    "pd.read_csv('atlasreader_peaks.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#control analysis:\n",
    "\n",
    "\n",
    "# import some functionality\n",
    "from datetime import datetime\n",
    "\n",
    "now = datetime.now()\n",
    "print('Starting cell:',now.strftime(\"%H:%M:%S\"))\n",
    "import os\n",
    "import pip\n",
    "os.system('python3 -m pip install numpy')\n",
    "os.system('python3 -m pip install matplotlib')\n",
    "os.system('python3 -m pip install scipy')\n",
    "os.system('python3 -m pip install panda')\n",
    "os.system('python3 -m pip install nilearn')\n",
    "os.system('python3 -m pip install pickle')\n",
    "os.system('python3 -m pip install atlasreader')\n",
    "os.system('python3 -m pip install mne')\n",
    "#import os.path as op\n",
    "#import numpy as np\n",
    "#from numpy.linalg import inv\n",
    "#import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "from nilearn import image\n",
    "import os\n",
    "#from scipy.ndimage import gaussian_filter\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "now = datetime.now()\n",
    "print('Finishing cell:',now.strftime(\"%H:%M:%S\"))\n",
    "\n",
    "def list_files(startpath):\n",
    "    \"\"\" Simple function to show directory tree. \n",
    "    From: https://stackoverflow.com/questions/9727673/list-directory-tree-structure-in-python. \"\"\"\n",
    "    for root, dirs, files in os.walk(startpath):\n",
    "        level = root.replace(startpath, '').count(os.sep)\n",
    "        indent = ' ' * 4 * (level)\n",
    "        print('{}{}/'.format(indent, os.path.basename(root)))\n",
    "        subindent = ' ' * 4 * (level + 1)\n",
    "        for f in sorted(files):\n",
    "            print('{}{}'.format(subindent, f))\n",
    "            \n",
    "data_dir='/work/MEG_exam/82777/BIDS/' \n",
    "derivatives_dir=  '/work/MEG_exam/82777/BIDS/derivatives/'          \n",
    "list_files(derivatives_dir)\n",
    "\n",
    "\n",
    "from nilearn.glm.first_level import first_level_from_bids\n",
    "\n",
    "#BIDS directory\n",
    "data_dir='/work/MEG_exam/82777/BIDS/'\n",
    "# BIDS derivatives (contains preprocessed data)\n",
    "derivatives_dir='/work/MEG_exam/82777/BIDS/derivatives' \n",
    "# Name for experiment in the BIDS directory\n",
    "task_label = 'EPIsequencewords'\n",
    "# Label for data that are spatially aligned to the MNI152 template (i.e. spatially normalised)\n",
    "space_label ='MNI152NLin2009cAsym'\n",
    "#Run the function that can gather all the needed info from a BIDS folder\n",
    "models, models_run_imgs, models_events, models_confounds = \\\n",
    "    first_level_from_bids(\n",
    "        data_dir, task_label, derivatives_folder=derivatives_dir, n_jobs=6, verbose=1,\n",
    "        img_filters=[('desc', 'preproc')])\n",
    "\n",
    "#Print the data from the first participant as sanity check\n",
    "print(models_run_imgs[0])\n",
    "\n",
    "now = datetime.now()\n",
    "print('Finishing cell:',now.strftime(\"%H:%M:%S\"))\n",
    "\n",
    "\n",
    "\n",
    "confound_friston24 = ['trans_x','trans_y','trans_z',\n",
    "                 'rot_x','rot_y','rot_z','trans_x_derivative1','trans_y_derivative1','trans_z_derivative1',\n",
    "                 'rot_x_derivative1','rot_y_derivative1','rot_z_derivative1','trans_x_power2','trans_y_power2','trans_z_power2',\n",
    "                 'rot_x_power2','rot_y_power2','rot_z_power2']\n",
    "\n",
    "confound_friston24_GSR = ['global_signal','global_signal_derivative1','global_signal_power2','global_signal_derivative1_power2','trans_x','trans_y','trans_z',\n",
    "                 'rot_x','rot_y','rot_z','trans_x_derivative1','trans_y_derivative1','trans_z_derivative1',\n",
    "                 'rot_x_derivative1','rot_y_derivative1','rot_z_derivative1','trans_x_power2','trans_y_power2','trans_z_power2',\n",
    "                 'rot_x_power2','rot_y_power2','rot_z_power2']\n",
    "\n",
    "# Subset confounds with selection\n",
    "for ii in range(len(models_confounds)):\n",
    "    confounds1=models_confounds[ii][:].copy()\n",
    "    for i in range(len(confounds1)):\n",
    "        confounds2=confounds1[i].copy()\n",
    "        confounds2=confounds2[confound_friston24_GSR]\n",
    "        #Removing NAs in the first row.\n",
    "        confounds2.loc[0,:]=confounds2.loc[1,:]\n",
    "        confounds1[i]=confounds2\n",
    "    models_confounds[ii][:]=confounds1\n",
    "\n",
    "\n",
    "#Print new confounds, for first participant, first run\n",
    "print(models_confounds[0][0].columns)\n",
    "\n",
    "now = datetime.now()\n",
    "print('Finishing cell:',now.strftime(\"%H:%M:%S\"))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Print model confounds for first participant, first run\n",
    "print(models_events[0][0].columns)\n",
    "\n",
    "events_sub= ['onset','duration','trial_type']\n",
    "\n",
    "\n",
    "\n",
    "# Subset confounds with selection\n",
    "for ii in range(len(models_events)):\n",
    "    events1=models_events[ii][:]\n",
    "    for i in range(len(events1)):\n",
    "        events2=events1[i]\n",
    "        events2=events2[events_sub]\n",
    "        events1[i]=events2\n",
    "    models_events[ii][:]=events1\n",
    "\n",
    "\n",
    "#Print new confounds, for first participant, first run\n",
    "print(models_events[0][0].columns)\n",
    "\n",
    "now = datetime.now()\n",
    "print('Finishing cell:',now.strftime(\"%H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "now = datetime.now()\n",
    "print('Starting cell:',now.strftime(\"%H:%M:%S\"))\n",
    "\n",
    "fig, axes = plt.subplots(nrows=5, ncols=5, figsize=(20, 20)) \n",
    "i = -1\n",
    "model_and_args = zip(models, models_run_imgs, models_events, models_confounds)\n",
    "for m_idx, (model, imgs, events, confounds) in enumerate(model_and_args):\n",
    "\n",
    "    # fit the GLM, recall that the model variable is a FirstLevelModel object\n",
    "    model.fit(imgs, events, confounds)\n",
    "    # compute the contrast of interest and make a map of z-values\n",
    "    model.zmap = model.compute_contrast('word_neu-(word_pos+word_neg)')\n",
    "    #Plot each thresholded analysis\n",
    "    plotting.plot_glass_brain(model.zmap, cmap='jet',colorbar=True, threshold=p001_unc,\n",
    "                              title=('sub-' + model.subject_label),\n",
    "                              axes=axes[int(m_idx / 5), int(m_idx % 5)],\n",
    "                              plot_abs=False, display_mode='x')\n",
    "\n",
    "   \n",
    "fig.suptitle('subjects z_map image diff (unc p<0.001)')\n",
    "plotting.show()\n",
    "\n",
    "\n",
    "now = datetime.now()\n",
    "\n",
    "print('Finishing cell:',now.strftime(\"%H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save results:\n",
    "import pickle\n",
    "f = open('/work/MEG_exam/WordFace_first_level_modelss.pkl', 'rb')\n",
    "models, models_run_imgs, models_events, models_confounds = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#group level\n",
    "from nilearn.glm.second_level import SecondLevelModel\n",
    "#We will simply add the models estimated above to the second level\n",
    "\n",
    "#second_level_input = models\n",
    "\n",
    "#NB idx11 has different resolution for some reason\n",
    "second_level_input = models[0:11]+models[12:]\n",
    "\n",
    "#Adding the smoothing parameter\n",
    "second_level_model = SecondLevelModel(smoothing_fwhm=8.0)\n",
    "second_level_model = second_level_model.fit(second_level_input)\n",
    "\n",
    "print(second_level_model)\n",
    "\n",
    "now = datetime.now()\n",
    "print('Finishing cell:',now.strftime(\"%H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NB, variable names used in contrasts have to be the same as those in events file.\n",
    "zmap_g = second_level_model.compute_contrast(\n",
    "    first_level_contrast='word_neu-(word_pos+word_neg)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot\n",
    "from nilearn.plotting import plot_stat_map\n",
    "import matplotlib\n",
    "from scipy.stats import norm\n",
    "p001_unc = norm.isf(0.001)\n",
    "fig = plt.figure(figsize=(10, 5))\n",
    "\n",
    "plotting.plot_glass_brain(zmap_g, cmap='PiYG',colorbar=True, threshold=p001_unc,\n",
    "                          title='Group level effect of [word_neu-(word_pos+word_neg)] effect (unc p < 0.001)',\n",
    "                          plot_abs=False, figure = fig, display_mode = \"lyrz\")\n",
    "plt.show()\n",
    "\n",
    "plot_stat_map(zmap_g, cmap='cold_hot',threshold=p001_unc, cut_coords=[-30,-20,-10,0,10,20,30],\n",
    "              display_mode='z',  black_bg=False,\n",
    "              title='Group [cword_neu-(word_pos+word_neg)] effect (unc p < 0.001)')\n",
    "plt.show()\n",
    "\n",
    "now = datetime.now()\n",
    "print('Finishing cell:',now.strftime(\"%H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#corrected plots:\n",
    "from nilearn.glm import threshold_stats_img\n",
    "from nilearn.plotting import plot_stat_map\n",
    "from nilearn.reporting import get_clusters_table\n",
    "from nilearn.image import mean_img\n",
    "\n",
    "thresholded_map, threshold = threshold_stats_img(\n",
    "    zmap_g, alpha=0.05, height_control='bonferroni')\n",
    "print('The p<.05 FWER-corrected threshold is %.3g' % threshold)\n",
    "\n",
    "plotting.plot_glass_brain(zmap_g, cmap='PiYG',colorbar=True, threshold=threshold,\n",
    "                          title='Group [word_neu-(word_pos+word_neg)] effect (p<0.05,Bonferroni-corrected)', display_mode = \"lyrz\",\n",
    "                          plot_abs=False)\n",
    "plt.show()\n",
    "\n",
    "# Make a table of cluster coordinates.\n",
    "table = get_clusters_table(zmap_g, stat_threshold=threshold)\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tables:\n",
    "import pandas as pd\n",
    "from atlasreader import create_output\n",
    "create_output(zmap_g, voxel_thresh=threshold, cluster_extent=0,direction='both')\n",
    "#Atlasreader automatically saves results to both .png-files and a csv-file. Look in your working directory.\n",
    "pd.read_csv('atlasreader_peaks.csv')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
